---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

````{admonition} Announcements & Reminders
:class: note
:class: dropdown


1. Final exam scheduled
    - **Monday June 3, 2pm***
    - 3h exam + 15min reading time
    - Melville Hall, building 12

2. Don't forget about the **Quiz 4** on **Monday, May 6**

3. Starting today with review of unconstrained optimization

````

# üìñ Convexity and uniqueness of optimizers

<small>‚è± <span class="eta"></span> | <span class="words"></span> words</small>

A path to **globally sufficient conditions** for optimality is through establishing the shape of the objective function

- Concave functions $\rightarrow$ local maxima are global maxima
- Convex functions $\rightarrow$ local minima are global minima
- Strict concavity/convexity $\rightarrow$ uniqueness of the maximum/minimum


Convexity / concavity are referred to as *shape restrictions*

- Convexity is a shape property for sets
- Convexity and concavity are shape properties for functions

## Convex Sets

```{admonition} Definition
:class: caution
:name: convex-set

A set $C \subset \mathbb{R}^K$ is called ***convex*** if
%
$$
%
x, y \text{ in } C \text{ and } 0 \leq \lambda \leq 1
\; \implies \;
\lambda x + (1 - \lambda) y \in C
%
$$

```

Convexity $\iff$ line between any two points in $C$ lies in $C$

```{figure} _static/plots/convex.png
:width: 45%

Convex set
```

A non-convex set

```{figure} _static/plots/non_convex.png
:width: 45%

Non-convex set
```

```{admonition} Example
:class: tip

The "positive cone" $P := \{ x \in \mathbb{R}^K \colon x  \geq 0 \}$ is convex

```

````{admonition} Proof
:class: dropdown

To see this, pick any $x$, $y$ in $P$ and any $\lambda \in [0, 1]$

Let $z := \lambda x + (1 - \lambda) y$ and let $z_k :=
e_k' z$

Since 
%
- $z_k = \lambda x_k + (1 - \lambda) y_k$
- $x_k \geq 0$ and $y_k \geq 0$

It is clear that $z_k \geq 0$ for all $k$

Hence $z \in P$ as claimed

````

```{admonition} Example
:class: tip

Every $\epsilon$-ball in $\mathbb{R}^K$ is convex.
```

````{admonition} Proof
:class: dropdown

Fix $a \in \mathbb{R}^K$, $\epsilon > 0$ and let
$B_\epsilon(a)$ be the $\epsilon$-ball

Pick any $x$, $y$ in $B_\epsilon(a)$ and any $\lambda \in [0, 1]$

The point $\lambda x + (1 - \lambda) y$ lies in
$B_\epsilon(a)$ because
%
$$
%
\| \lambda x + (1 - \lambda) y - a \|
= \| \lambda x - \lambda a 
+ (1 - \lambda) y - (1 - \lambda) a \| \leq
\\
\leq \| \lambda x - \lambda a \|
+ \| (1 - \lambda) y - (1 - \lambda) a \| =
\\
= \lambda \| x - a \|
+ (1 - \lambda) \| y - a \| <>
\\
< \lambda \epsilon + (1 - \lambda) \epsilon =
\\
= \epsilon
%
$$
%

````

```{admonition} Example
:class: tip

Let $p \in \mathbb{R}^K$ and let $M$ be the "half-space"

%
$$
%
M := \{ x \in \mathbb{R}^K \colon p ' x \leq m\}
%
$$
%

The set $M$ is convex
```

````{admonition} Proof
:class: dropdown

Let $p$, $m$ and $M$ be as described

Fix $x$, $y$ in $M$ and $\lambda \in [0, 1]$ 

Then $\lambda x + (1 - \lambda) y \in M$ because
%
$$
%
p'[\lambda x + (1 - \lambda) y ] =
\lambda p'x + (1 - \lambda) p'y 
\leq \lambda m + (1 - \lambda) m
= m
%
$$
%

Hence $M$ is convex
````


```{admonition} Fact
:class: important

If $A$ and $B$ are convex, then so is $A \cap B$
```

````{admonition} Proof
:class: dropdown

Let $A$ and $B$ be convex and let $C := A \cap B$

Pick any $x$, $y$ in $C$ and any $\lambda \in [0, 1]$

Set 
%
$$z := \lambda x + (1 - \lambda) y$$
%

Since $x$ and $y$ lie in $A$ and $A$ is convex we have $z
\in A$

Since $x$ and $y$ lie in $B$ and $B$ is convex we have $z
\in B$

Hence $z \in A \cap B$

````

```{admonition} Example
:class: tip

Let $p \in \mathbb{R}^K$ be a vector of prices and consider the budget set
%
$$
%
B(m) := \{ x \in \mathbb{R}^K \colon x  \geq 0 \text{ and }
p' x \leq m\}
%
$$
%

The budget set $B(m)$ is convex
```

````{admonition} Proof
:class: dropdown

To see this, note that $B(m) = P \cap M$ where
%
$$
%
P := \{ x \in \mathbb{R}^K \colon x  \geq 0 \}
\qquad
M := \{ x \in \mathbb{R}^K \colon p ' x \leq m\}
%
$$
%

We already know that
%
- $P$ and $M$ are convex, intersections of convex sets are convex

Hence $B(m)$ is convex

````



## Convex Functions

Let $A \subset \mathbb{R}^K$ be a convex set and let $f$ be a function from $A$ to $\mathbb{R}$

```{admonition} Definition
:class: caution
:name: convex-function

$f$ is called ***convex*** if 
%
$$
%
f(\lambda x + (1 - \lambda) y)
\leq \lambda f(x) + (1 - \lambda) f(y)
%
$$
%
for all $x, y \in A$ and all $\lambda \in [0, 1]$

$f$ is called ***strictly convex*** if 
%
$$
%
f(\lambda x + (1 - \lambda) y)
< \lambda f(x) + (1 - \lambda) f(y)
%
$$
%
for all $x, y \in A$ with $x \ne y$ and all $\lambda \in (0, 1)$

```

```{figure} _static/plots/convex_function.png
:name: 

A strictly convex function on a subset of $\mathbb{R}$
```

```{admonition} Fact
:class: important

$f \colon A \to \mathbb{R}$ is convex if and only if its ***epigraph*** (aka supergraph)

$$
E_f := \{ (x, y) \in A \times \mathbb{R} \colon f(x) \leq y \}
$$

is a convex subset of $\mathbb{R}^K \times \mathbb{R}$
```

```{figure} _static/plots/epigraph.png
:width: 50%

Convex epigraph/supergraph of a function
```

```{figure} _static/plots/qform_pd.png
:width: 50%

A strictly convex function on a subset of $\mathbb{R}^2$
```

```{admonition} Example
:class: tip

$f(x) = \|x\|$ is convex on $\mathbb{R}^K$ 
```

````{admonition} Proof
:class: dropdown

To see this recall that, by the properties of norms,
%
$$
%
\|\lambda x + (1 - \lambda) y\|
\leq \|\lambda x\| + \|(1 - \lambda) y\|
\\
= \lambda \|x\| + (1 - \lambda) \|y\|
%
$$
%
That is,
%
$$
%
f(\lambda x + (1 - \lambda) y)
\leq 
\lambda f(x) + (1 - \lambda) f(y)
%
$$
%

````

```{admonition} Fact
:class: important

If $A$ is $K \times K$ and positive definite, then 
%
$$
%
Q(x) = x' A x
\qquad (x \in \mathbb{R}^K)
%
$$
%
is strictly convex on $\mathbb{R}^K$
```

````{admonition} Proof
:class: dropdown

Proof: Fix $x, y \in \mathbb{R}^K$ with $x \ne y$ and $\lambda \in (0, 1)$

**Exercise:** Show that 
%
$$
%
\lambda Q(x) + (1 - \lambda) Q(y)
- Q(\lambda x + (1 - \lambda) y)
\\
= \lambda (1 - \lambda) (x - y)' A (x - y)
%
$$
%

Since $x - y \ne 0$ and $0 < \lambda < 1$, the right
hand side is $> 0$

Hence
%
$$
%
\lambda Q(x) + (1 - \lambda) Q(y)
> Q(\lambda x + (1 - \lambda) y)
%
$$
%
````


## Concave Functions

Let $A \subset \mathbb{R}^K$ be a convex and let $f$ be a function from $A$ to $\mathbb{R}$

```{admonition} Definition
:class: caution

$f$ is called ***concave*** if 

$$
f(\lambda x + (1 - \lambda) y)
\geq \lambda f(x) + (1 - \lambda) f(y)
$$

for all $x, y \in A$ and all $\lambda \in [0, 1]$

$f$ is called ***strictly concave*** if 

$$
f(\lambda x + (1 - \lambda) y)
> \lambda f(x) + (1 - \lambda) f(y)
$$

for all $x, y \in A$ with $x \ne y$ and all $\lambda \in (0, 1)$

```

**Exercise:** Show that 
%
1. $f$ is concave if and only if $-f$ is convex

9. $f$ is strictly concave if and only if $-f$ is strictly convex

```{admonition} Fact
:class: important

$f \colon A \to \mathbb{R}$ is concave if and only if its ***hypograph*** (aka subgraph)
%
$$
%
H_f := \{ (x, y) \in A \times \mathbb{R} \colon f(x) \geq y\}
%
$$
%
is a convex subset of $\mathbb{R}^K \times \mathbb{R}$
```

```{figure} _static/plots/hypograph.png
:width: 50%

Convex hypograph/subgraph of a function
```


## Preservation of Shape

Let $A \subset \mathbb{R}^K$ be convex and let $f$ and $g$ be functions from $A$
to $\mathbb{R}$

```{admonition} Fact
:class: important

If $f$ and $g$ are convex (resp., concave) and $\alpha \geq 0$, then
%
- $\alpha f$ is convex (resp., concave)
- $f + g$ is convex (resp., concave)

If $f$ and $g$ are strictly convex (resp., strictly concave) and $\alpha > 0$, then
%
- $\alpha f$ is strictly convex (resp., strictly concave)
- $f + g$ is strictly convex (resp., strictly concave)
```

````{admonition} Proof
:class: dropdown

Let's prove that $f$ and $g$ convex $\implies h := f + g$ convex

Pick any $x, y \in A$ and $\lambda \in [0, 1]$

We have
%
$$
%
& 
h(\lambda x + (1 - \lambda) y)
= f(\lambda x + (1 - \lambda) y)
+ g(\lambda x + (1 - \lambda) y)
\\ &
\leq 
\lambda f(x) + (1 - \lambda) f(y)
+
\lambda g(x) + (1 - \lambda) g(y)
\\ &
=
\lambda [f(x) + g(x)]
+ (1 - \lambda) [f(y) + g(y)]
\\ &
=
\lambda h(x) + (1 - \lambda) h(y)
%
$$
%

Hence $h$ is convex
$\blacksquare$
````


## Hessian based shape criterion

```{admonition} Fact
:class: important
:name: convexity-hessian-criterion

If $f \colon A \to \mathbb{R}$ is a $C^2$ function where $A \subset \mathbb{R}^K$ is open and convex, then
%
1. $Hf(x)$ positive semi-definite (nonnegative definite) for all $x \in A$ $\iff f$ convex
2. $Hf(x)$ negative semi-definite (nonpositive definite) for all $x \in A$ $\iff f$ concave

In addition,
%
1. $Hf(x)$ positive definite for all $x \in A$ $\implies f$ strictly convex
2. $Hf(x)$ negative definite for all $x \in A$ $\implies f$ strictly concave
```

Proof: Omitted

```{admonition} Example
:class: tip

Let $A := (0, \infty) \times (0, \infty)$ and let $U \colon A \to \mathbb{R}$ be the utility function
%
$$
%
U(c_1, c_2) = \alpha \ln c_1 + \beta \ln c_2
%
$$
%

Assume that $\alpha$ and $\beta$ are both strictly positive

**Exercise:** Show that the Hessian at $c := (c_1, c_2) \in A$ has the form
%
$$
%
H(c)
:=
\begin{pmatrix}
- \frac{\alpha}{c_1^2} & 0 \\
0 & - \frac{\beta}{c_2^2} 
\end{pmatrix}
%
$$
%

**Exercise:** Show that any diagonal matrix with strictly negative elements along
the principle diagonal is negative definite

Conclude that $U$ is strictly concave on $A$
```


## Sufficiency of first order conditions

There two advantages of convexity/concavity:

1. **Sufficiency of first order conditions** for optimality
2. **Uniqueness of optimizers** with strict convexity/concavity

```{admonition} Fact
:class: important

Let $A \subset \mathbb{R}^K$ be convex set and let $f \colon A \to \mathbb{R}$ be concave/convex differentiable function.

Then $x^* \in A$ is a minimizer/minimizer of $f$ on $A$ if and only if $x^*$ is a stationary point of $f$ on $A$.

```

- Note that weak convexity/concavity is enough for this result: first order condition becomes sufficient
- However, the optimizer may not be unique (see below results on uniqueness)

````{admonition} Proof
:class: dropdown

See {cite:ps}`sundaram1996`, Theorem 7.15

````



## Uniqueness of Optimizers

```{admonition} Fact
:class: important
:name: general-uniqueness

Let $A \subset \mathbb{R}^K$ be convex set and let $f \colon A \to \mathbb{R}$

1. If $f$ is strictly convex, then $f$ has at most one minimizer on $A$

9. If $f$ is strictly concave, then $f$ has at most one maximizer on $A$

```


Interpretation, strictly concave case:

- we don't know in general if $f$ has a maximizer

- but if it does, then it has exactly one

- in other words, we have uniqueness

````{admonition} Proof
:class: dropdown

Proof for the case where $f$ is strictly concave:

Suppose to the contrary that 
%
- $a$ and $b$ are distinct points in $A$

- both are maximizers of $f$ on $A$

By the def of maximizers, $f(a) \geq f(b)$ and $f(b) \geq f(a)$

Hence we have $f(a) = f(b)$

By strict concavity, then
%
$$
%
f\left( \frac{1}{2} a + \frac{1}{2} b \right)
> \frac{1}{2} f( a) + \frac{1}{2} f( b)
= \frac{1}{2} f( a) + \frac{1}{2} f( a)
= f(a)
%
$$
%

This contradicts the assumption that $a$ is a maximizer

````

### Sufficient Condition for Uniqueness

We can now restate more precisely optimization results stated in the
introductory lectures

Let $f \colon A \to \mathbb{R}$ be a $C^2$ function where $A \subset \mathbb{R}^K$
is open, convex

Recall that $x^* \in A$ is a stationary point of $f$ if
%
$$
%
\frac{\partial}{\partial x_i} 
f(x^*)
= 0
\quad \text{for all $i$ in } 1, \ldots, K
%
$$
%

```{admonition} Fact
:class: important
:name: general-stationary-uniqueness

Let $A \subset \mathbb{R}^K$ be convex set, let $f \colon A \to \mathbb{R}$, and $x^* \in A$ stationary, then
%
1. $f$ strictly concave $\implies$ $x^*$ is the unique maximizer of $f$ on $A$

2. $f$ strictly convex $\implies$ $x^*$ is the unique
minimizer of $f$ on $A$
```

```{figure} _static/plots/concave_max.png
:width: 75% 

Unique maximizer for a strictly concave function
```






## Roadmap for unconstrained optimization

1. Assuming that the domain of the objective function is the whole space, check that it is continuous and for derivative based methods twice continuously differentiable

2. Derive the gradient and Hessian of the objective function. If it can be shown that the function is globally concave or convex, checking SOC (below) is not necessary, and global optima can be established

3. Find all stationary points by solving FOC

4. Check SOC to determine whether found stationary points are (local) maxima or minima and filter out saddle points

5. Assess whether any of the local optima are global by comparing function values at these points, and inspecting the shape of the function to determine if its value anywhere exceeds the best local optimum (limits at the positive and negative infinities, possible vertical asymptotes, etc.)



## References and reading

```{dropdown} References
- Simon & Blume: 13.1, 13.2, 13.3, 14.1, 14.3, 14.4, 14.5, 14.8, whole of chapter 17
- Sundaram: 1.4, 1.5, 2.1, 2.2, 4.1 to 4.4
```


