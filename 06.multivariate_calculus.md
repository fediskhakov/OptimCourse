---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

```{note}

- start with matrices and operations on matrices
- then all the mutivariate differentiation

- differentiability, derivatives
- continuity <--> differentiability



- definition of derivative

- total derivative
- derivative in a particular direction
- steepest descent

- end with the logit example: compute hessian using matrix operations
- (to be continued in the lecture on convex optimization)
- problems set on solving FOCs from the exam (do not loose stationary points)
```

# üìñ Multivariate calculus

<small>‚è± <span class="eta"></span> | <span class="words"></span> words</small>


## Derivatives

```{admonition} Definition
:class: caution
:name: derivative

Let $f \colon (a, b) \to \mathbb{R}$ and let $x \in (a, b)$

Let $H$ be all sequences $\{h_n\}$ such that 
$h_n \ne 0$ and $h_n \to 0$

If there exists a constant $f'(x)$ such that
%
$$
\frac{f(x + h_n) - f(x)}{h_n} \to f'(x)
$$
%
for every $\{h_n\} \in H$, then 

- $f$ is said to be **differentiable** at $x$
- $f'(x)$ is called the **derivative** of $f$ at $x$ 

```

```{figure} _static/plots/derivative.png
```

```{admonition} Example
:class: tip

Let $f \colon \mathbb{R} \to \mathbb{R}$ be defined by $f(x) = x^2$

Fix any $x \in \mathbb{R}$ and any $h_n \to 0$ with $n \to \infty$

We have
%    
$$
\frac{f(x + h_n) - f(x)}{h_n} 
= \frac{(x + h_n)^2 - x^2}{h_n} =
$$
$$
= \frac{x^2 + 2xh_n + h_n^2 - x^2}{h_n}
= 2x + h_n
$$
$$
\text{therefore }
f'(x)
= \lim_{n \to \infty} (2x + h_n)
= 2x
$$
%
```

```{admonition} Example
:class: tip

Let $f \colon \mathbb{R} \to \mathbb{R}$ be defined by $f(x) = |x|$

This function is not differentiable at $x=0$

Indeed, if $h_n = 1/n$, then
%
$$
\frac{f(0 + h_n) - f(0)}{h_n} 
= \frac{|0 + 1/n| - |0|}{1/n} \to 1
$$
%
On the other hand, if $h_n = -1/n$, then
%
$$
\frac{f(0 + h_n) - f(0)}{h_n} 
= \frac{|0 - 1/n| - |0|}{-1/n} \to -1
$$
%
```

## Differentiability and continuity

```{admonition} Fact

$\iff$

```


(ref-taylor)=
## Taylor series

Loosely speaking, if $f \colon \mathbb{R} \to \mathbb{R}$ is suitably
differentiable at $a$, then
%
$$
f(x) \approx f(a) + f'(a)(x-a) 
$$
%
for $x$ very close to $a$,
%
$$
f(x) \approx f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 
$$
%
on a slightly wider interval, etc.

These are the 1st and 2nd order **Taylor series approximations**
to $f$ at $a$ respectively

As the order goes higher we get better approximation

```{figure} _static/plots/taylor_4.png
:width: 60%

4th order Taylor series for $f(x) = \sin(x)/x$ at 0
```

```{figure} _static/plots/taylor_6.png
:width: 60%

6th order Taylor series for $f(x) = \sin(x)/x$ at 0
```

```{figure} _static/plots/taylor_8.png
:width: 60%

8th order Taylor series for $f(x) = \sin(x)/x$ at 0
```

```{figure} _static/plots/taylor_10.png
:width: 60%

10th order Taylor series for $f(x) = \sin(x)/x$ at 0
```





## Matrices and operations on matrices


```{admonition} Definition
:class: caution

***matrix***

:::{math}
\left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1K} \\
a_{21} & a_{22} & \cdots & a_{2K} \\
\vdots & \vdots & & \vdots \\
a_{N1} & a_{N2} & \cdots & a_{NK} 
\end{array}
\right)
:::
```


## What is a matrix?

A **matrix** is an array of numbers or variables. It is organised into rows and columns. These form its **dimensions**.

An $(n \times m)$ matrix has $n$ rows and $m$ columns. Note that, while it is possible that $n=m$, it is also possible that $n \neq m$. When $n=m$, we say that the matrix is a **square matrix**.

An $(n \times m)$ matrix takes the following form:

$$
A=\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right)
$$


### Scalars and vectors

A **scalar** is a real number $(a \in \mathbb{R})$.

A **column vector** is an $(n \times 1)$ matrix of the form

$$
A=\left(\begin{array}{c}
a_{11} \\
a_{21} \\
a_{31} \\
\vdots \\
a_{n 1}
\end{array}\right)
$$

A **row vector** is a $(1 \times m)$ matrix of the form

$$
A=\left(\begin{array}{lllll}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m}
\end{array}\right) .
$$


## An overview of matrix arithmetic

- Scalar multiplication of a matrix
- Matrix addition
- Matrix subtraction
- Matrix multiplication: The inner, or dot, product
- The transpose of a matrix and matrix symmetry
- The additive inverse of a matrix and the null matrix
- The multiplicative inverse of a matrix and the identity matrix
- Idempotent matrices
- Vector inequalities



### Scalar multiplication

Suppose that $c \in \mathbb{R}$ and $A$ is an $(n \times m)$ matrix takes the following form:

$$
A=\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right)
$$

We will assume that $a_{i j} \in \mathbb{R}$ for all

$$
(i, j) \in\{1,2, \cdots, n\} \times\{1,2, \cdots, m\} .
$$


The scalar pre-product of this constant with this matrix is given by

$$
\begin{aligned}
c A & =c\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right) \\[20pt]
& =\left(\begin{array}{ccccc}
c a_{11} & c a_{12} & c a_{13} & \cdots & c a_{1 m} \\
c a_{21} & c a_{22} & c a_{23} & \cdots & c a_{2 m} \\
c a_{31} & c a_{32} & c a_{33} & \cdots & c a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
c a_{n 1} & c a_{n 2} & c a_{n 3} & \cdots & c a_{n m}
\end{array}\right)
\end{aligned}
$$


The scalar post-product of the matrix with constant is given by

$$
\begin{aligned}
A c & =\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right) c \\[20pt]
& =\left(\begin{array}{ccccc}
c a_{11} & c a_{12} & c a_{13} & \cdots & c a_{1 m} \\
c a_{21} & c a_{22} & c a_{23} & \cdots & c a_{2 m} \\
c a_{31} & c a_{32} & c a_{33} & \cdots & c a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
c a_{n 1} & c a_{n 2} & c a_{n 3} & \cdots & c a_{n m}
\end{array}\right)
\end{aligned}
$$

Note that $c A=A c$. As such, we can just talk about the **scalar product** of a constant with a matrix, without specifying the order in which the multiplication takes place.

### Some examples of scalar multiplication of a matrix

The following examples come from {cite:ps}`asano2013` (pp. 222-224).

```{admonition} Example
:class: tip


$$
2 X=2\left(\begin{array}{ll}
1 & 1 \\
1 & 2
\end{array}\right)=\left(\begin{array}{ll}
2(1) & 2(1) \\
2(1) & 2(2)
\end{array}\right)=\left(\begin{array}{ll}
2 & 2 \\
2 & 4
\end{array}\right)
$$
```

```{admonition} Example
:class: tip


$$
3 Y=3\left(\begin{array}{ll}
2 & 1 \\
2 & 4
\end{array}\right)=\left(\begin{array}{ll}
3(2) & 3(1) \\
3(2) & 3(4)
\end{array}\right)=\left(\begin{array}{cc}
6 & 3 \\
6 & 12
\end{array}\right)
$$
```

```{admonition} Example
:class: tip


$$
2 Z=2\left(\begin{array}{cc}
-1 & -2 \\
3 & 1
\end{array}\right)=\left(\begin{array}{cc}
2(-1) & 2(-2) \\
2(3) & 2(1)
\end{array}\right)=\left(\begin{array}{cc}
-2 & -4 \\
6 & 2
\end{array}\right)
$$
```


The following examples come from {cite:ps}`sydsaeter2006` (pp. 555-556).

```{admonition} Example
:class: tip


$$
\begin{gathered}
3 A=2\left(\begin{array}{ccc}
1 & 2 & 0 \\
4 & -3 & 1
\end{array}\right)=\left(\begin{array}{ccc}
3(1) & 3(2) & 3(0) \\
3(4) & 3-(3) & 3(1)
\end{array}\right) \\
=\left(\begin{array}{ccc}
3 & 6 & 0 \\
12 & -9 & 3
\end{array}\right)
\end{gathered}
$$
```

```{admonition} Example
:class: tip


$$
\begin{aligned}
& \left(\frac{-1}{2}\right) B=2\left(\begin{array}{lll}
0 & 1 & 2 \\
1 & 0 & 2
\end{array}\right)=\left(\begin{array}{ccc}
\left(\frac{-1}{2}\right)(0) & \left(\frac{-1}{2}\right)(1) & \left(\frac{-1}{2}\right)(2) \\
\left(\frac{-1}{2}\right)(1) & \left(\frac{-1}{2}\right)(0) & \left(\frac{-1}{2}\right)(2)
\end{array}\right) \\
& =\left(\begin{array}{ccc}
0 & \frac{-1}{2} & -1 \\
\frac{-1}{2} & 0 & -1
\end{array}\right)
\end{aligned}
$$
```


### Matrix addition

The sum of two matrices is only defined if the two matrices have exactly the same dimensions.  

Suppose that $A$ is an $(n \times m)$ matrix that takes the following form:

$$
A=\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right)
$$

Suppose that $B$ is an $(n \times m)$ matrix that takes the following form:

$$
B=\left(\begin{array}{ccccc}
b_{11} & b_{12} & b_{13} & \cdots & b_{1 m} \\
b_{21} & b_{22} & b_{23} & \cdots & b_{2 m} \\
b_{31} & b_{32} & b_{33} & \cdots & b_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
b_{n 1} & b_{n 2} & b_{n 3} & \cdots & b_{n m}
\end{array}\right)
$$


The **matrix sum** $(A+B)$ is an $(n \times m)$ matrix that takes the following form:

$$
\begin{aligned}
A+B
&=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 m} \\
a_{21} & a_{22} & \cdots & a_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n m}
\end{array}\right)+\left(\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 m} \\
b_{21} & b_{22} & \cdots & b_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
b_{n 1} & b_{n 2} & \cdots & b_{n m}
\end{array}\right) \\[20pt]
&=\left(\begin{array}{cccc}
a_{11}+b_{11} & a_{12}+b_{12} & \cdots & a_{1 m}+b_{1 m} \\
a_{21}+b_{21} & a_{22}+b_{22} & \cdots & a_{2 m}+b_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1}+b_{n 1} & a_{n 2}+b_{n 2} & \cdots & a_{n m}+b_{n m}
\end{array}\right)
\end{aligned}
$$

Note that $A+B=B+A$. (Exercise: Convince yourself of the validity of this claim.)


### Some examples of matrix addition

- Suppose that $A$ is an $(m \times n)$ matrix, $B$ is an $(n \times m)$ matrix and $C$ is an $(n \times p)$ matrix, where $m \neq n, m \neq p$ and $n \neq p$.
- Example 1: Neither the matrix sum $A+B$ nor the matrix sum $B+A$ are defined.
- Example 2: Neither the matrix sum $A+C$ nor the matrix sum $C+A$ are defined.
- Example 3: Neither the matrix sum $B+C$ nor the matrix sum $C+B$ are defined.


The following examples come from {cite:ps}`asano2013` (pp. 222-224).

```{admonition} Example
:class: tip


$$
X+Y=\left(\begin{array}{ll}
1 & 1 \\
1 & 2
\end{array}\right)+\left(\begin{array}{ll}
1 & 0 \\
1 & 2
\end{array}\right)=\left(\begin{array}{ll}
1+1 & 1+0 \\
1+1 & 2+2
\end{array}\right)=\left(\begin{array}{ll}
2 & 1 \\
2 & 4
\end{array}\right)
$$
```

```{admonition} Example
:class: tip


$$
\begin{aligned}
& X+Z=\left(\begin{array}{ll}
1 & 1 \\
1 & 2
\end{array}\right)+\left(\begin{array}{ll}
-1 & 3 \\
-2 & 1
\end{array}\right)=\left(\begin{array}{ll}
1+(-1) & 1+3 \\
1+(-2) & 2+1
\end{array}\right) 
 =\left(\begin{array}{cc}
0 & 4 \\
-1 & 3
\end{array}\right)
\end{aligned}
$$
```

The following example comes from {cite:ps}`sydsaeter2006` (pp. 555-556).
```{admonition} Example
:class: tip


$$
\begin{gathered}
M+N=\left(\begin{array}{ccc}
1 & 2 & 0 \\
4 & -3 & -1
\end{array}\right)+\left(\begin{array}{lll}
0 & 1 & 2 \\
1 & 0 & 2
\end{array}\right) 
=\left(\begin{array}{ccc}
1+0 & 2+1 & 0+2 \\
4+1 & -3+0 & -1+2
\end{array}\right) 
=\left(\begin{array}{ccc}
1 & 3 & 2 \\
5 & -3 & 1
\end{array}\right)
\end{gathered}
$$
```

### Matrix subtraction

Matrix subtraction involves a combination of (i) scalar multiplication of a matrix, and (ii) matrix addition.

As with matrix addition, the difference of two matrices is only defined if the two matrices have exactly the same dimensions.

Suppose that $A$ and $B$ are both $(n \times m)$ matrices. The difference between $A$ and $B$ is defined to be

$$
A-B=A+(-1) B
$$

Since $A$ and $B$ are both $(n \times m)$ matrices, the matrix difference $(A-B)$ is an $(n \times m)$ matrix that takes the following form:

$$
\begin{aligned}
A-B &= A+(-1) B \\[20pt]
&= \left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 m} \\
a_{21} & a_{22} & \cdots & a_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n m}
\end{array}\right)+(-1)\left(\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 m} \\
b_{21} & b_{22} & \cdots & b_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
b_{n 1} & b_{n 2} & \cdots & b_{n m}
\end{array}\right) \\[20pt]
&= \left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 m} \\
a_{21} & a_{22} & \cdots & a_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n m}
\end{array}\right)+\left(\begin{array}{cccc}
-b_{11} & -b_{12} & \cdots & -b_{1 m} \\
-b_{21} & -b_{22} & \cdots & -b_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
-b_{n 1} & -b_{n 2} & \cdots & -b_{n m}
\end{array}\right) \\[20pt]
&= \left(\begin{array}{cccc}
a_{11}-b_{11} & a_{12}-b_{12} & \cdots & a_{1 m}-b_{1 m} \\
a_{21}-b_{21} & a_{22}-b_{22} & \cdots & a_{2 m}-b_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1}-b_{n 1} & a_{n 2}-b_{n 2} & \cdots & a_{n m}-b_{n m}
\end{array}\right)
\end{aligned}
$$

In general, $A-B \neq B-A$. Thus matrix subtraction does not share all of the properties of matrix addition.

Exercise: Under what circumstances will $A-B=B-A$ ?


```{admonition} Example
:class: tip

The following example comes from {cite:ps}`asano2013` (pp. 222-224).

$$
\begin{aligned}
X-Y &=\left(\begin{array}{cc}
6 & 3 \\
6 & 12
\end{array}\right)-\left(\begin{array}{cc}
-2 & -4 \\
6 & 2
\end{array}\right) \\
& =\left(\begin{array}{cc}
6 & 3 \\
6 & 12
\end{array}\right)+(-1)\left(\begin{array}{cc}
-2 & -4 \\
6 & 2
\end{array}\right) \\
& =\left(\begin{array}{cc}
6 & 3 \\
6 & 12
\end{array}\right)+\left(\begin{array}{cc}
(-1)(-2) & (-1)(-4) \\
(-1)(6) & (-1)(2)
\end{array}\right) \\
& =\left(\begin{array}{cc}
6 & 3 \\
6 & 12
\end{array}\right)+\left(\begin{array}{cc}
2 & 4 \\
-6 & -2
\end{array}\right) \\
& =\left(\begin{array}{cc}
6+2 & 3+4 \\
6+(-6) & 12+(-2)
\end{array}\right) \\
& =\left(\begin{array}{cc}
8 & 7 \\
0 & 10
\end{array}\right)
\end{aligned}
$$

```


### Matrix multiplication

- The standard matrix product is the dot, or inner, product of two matrices.
- The dot product of two matrices is only defined for cases in which the number of columns of the first listed matrix is identical to the number of rows of the second listed matrix.
- If the dot product is defined, the solution matrix will have the same number of rows as the first listed matrix and the same number of columns as the second listed matrix.


Suppose that $X$ is an $(m \times n)$ matrix, $Y$ is an $(n \times m)$ matrix and $Z$ is an $(n \times p)$ matrix, where $m \neq n, m \neq p$ and $n \neq p$.
- The matrix product $X Y$ is defined and will be an $(m \times m)$ matrix.
- The matrix product $Y X$ is defined and will be an $(n \times n)$ matrix.
- The matrix product $X Z$ is defined and will be an $(m \times p)$ matrix.
- The matrix products $Z X, Y Z$ and $Z Y$ are not defined.


Suppose that $A$ is an $(n \times m)$ matrix that takes the following form:

$$
A=\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right)
$$

Suppose that $B$ is an $(m \times p)$ matrix that takes the following form:

$$
B=\left(\begin{array}{ccccc}
b_{11} & b_{12} & b_{13} & \cdots & b_{1 p} \\
b_{21} & b_{22} & b_{23} & \cdots & b_{2 p} \\
b_{31} & b_{32} & b_{33} & \cdots & b_{3 p} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
b_{m 1} & b_{m 2} & b_{m 3} & \cdots & b_{m p}
\end{array}\right)
$$


The **matrix product** $A B$ is defined and will be an $(n \times p)$ matrix. The solution matrix is given by

$$
\begin{aligned}
AB
&=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 m} \\
a_{21} & a_{22} & \cdots & a_{2 m} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n m}
\end{array}\right) \cdot\left(\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 p} \\
b_{21} & b_{22} & \cdots & b_{2 p} \\
\vdots & \vdots & \ddots & \vdots \\
b_{m 1} & b_{m 2} & \cdots & b_{m p}
\end{array}\right) \\[20pt]
&=\left(\begin{array}{ccccc}
\sum_{k=1}^{m} a_{1 k} b_{k 1} & \sum_{k=1}^{m} a_{1 k} b_{k 2} & \cdots & \sum_{k=1}^{m} a_{1 k} b_{k p} \\
\vdots & a_{2 k} b_{k 1} & \sum_{k=1}^{m} a_{2 k} b_{k 2} & \cdots & \sum_{k=1}^{m} a_{2 k} b_{k p} \\
\sum_{k=1}^{m} a_{n k} b_{k 1} & \sum_{k=1}^{m} a_{n k} b_{k 2} & \cdots & \sum_{k=1}^{m} a_{n k} b_{k p}
\end{array}\right)
\end{aligned}
$$

Note that, while it is possible for $A B=B A$ in some cases, in general we will have $A B \neq B A$. There are three reasons for this:
- First, $B A$ will not necessarily be defined even if $A B$ is defined.
- Second, even when both $A B$ and $B A$ are defined, they might have different dimensions.
- Third, even when both $A B$ and $B A$ are defined and have the same dimensions, they might have one or more different entries.


These examples come from {cite:ps}`bradley2008` (pp. 490-492).

```{admonition} Example
:class: tip


$$
\begin{aligned}
AB & =\left(\begin{array}{cc}
1 & 2 \\
-2 & 4
\end{array}\right) \cdot\left(\begin{array}{lll}
0 & 2 & 2 \\
1 & 0 & 5
\end{array}\right) \\
&=\left(\begin{array}{ccc}
(1)(0)+(2)(1) & (1)(2)+(2)(0) & (1)(2)+(2)(5) \\
(-2)(0)+(4)(1) & (-2)(2)+(4)(0) & (-2)(2)+(4)(5)
\end{array}\right) \\
&=\left(\begin{array}{ccc}
0+2 & 2+0 & 2+10 \\
0+4 & -4+0 & -4+20
\end{array}\right) \\
&=\left(\begin{array}{ccc}
2 & 2 & 12 \\
4 & -4 & 16
\end{array}\right)
\end{aligned}
$$
```

```{admonition} Example
:class: tip

The matrix product $B A$ is undefined because the number of columns in $B$ (which is three) does not equal the number of rows in $A$ (which is two).

Note that $A B \neq B A$.

```

```{admonition} Example
:class: tip


$$
\begin{aligned}
A C &=\left(\begin{array}{cc}
1 & 2 \\
-2 & 4
\end{array}\right) \cdot\left(\begin{array}{cc}
3 & -2 \\
5 & 0
\end{array}\right) \\
&=\left(\begin{array}{cc}
(1)(3)+(2)(5) & (1)(-2)+(2)(0) \\
(-2)(3)+(4)(5) & (-2)(-2)+(4)(0)
\end{array}\right) \\
&=\left(\begin{array}{cc}
3+10 & -2+0 \\
-6+20 & 4+0
\end{array}\right) \\
&=\left(\begin{array}{cc}
13 & -2 \\
14 & 4
\end{array}\right)
\end{aligned}
$$
```

```{admonition} Example
:class: tip


$$
\begin{aligned}
C A &=\left(\begin{array}{cc}
3 & -2 \\
5 & 0
\end{array}\right) \cdot\left(\begin{array}{cc}
1 & 2 \\
-2 & 4
\end{array}\right) \\
&=\left(\begin{array}{cc}
(3)(1)+(-2)(-2) & (3)(2)+(-2)(4) \\
(5)(1)+(0)(-2) & (5)(2)+(0)(4)
\end{array}\right) \\
&=\left(\begin{array}{cc}
3+4 & 6+(-8) \\
5+0 & 10+0
\end{array}\right) \\
&=\left(\begin{array}{cc}
7 & -2 \\
5 & 10
\end{array}\right)
\end{aligned}
$$

Note that $A C \neq C A$.
```


### Matrix transposition

Suppose that $A$ is an $(n \times m)$ matrix. The **transpose** of the matrix $A$, which is denoted by $A^{T}$, is the $(m \times n)$ matrix that is formed by taking the rows of $A$ and turning them into columns, without changing their order. In other words, the $i$ th column of $A^{T}$ is the ith row of $A$. This also means that the jth row of $A^{T}$ is the $j$ th column of $A$.


Suppose that $A$ is the $(n \times m)$ matrix that takes the following form:

$$
A=\left(\begin{array}{ccccc}
a_{11} & a_{12} & a_{13} & \cdots & a_{1 m} \\
a_{21} & a_{22} & a_{23} & \cdots & a_{2 m} \\
a_{31} & a_{32} & a_{33} & \cdots & a_{3 m} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & a_{n 3} & \cdots & a_{n m}
\end{array}\right)
$$

The **transpose** of the matrix $A$ is the $(m \times n)$ matrix that takes the following form:

$$
A^{T}=\left(\begin{array}{ccccc}
a_{11} & a_{21} & a_{31} & \cdots & a_{n 1} \\
a_{12} & a_{22} & a_{32} & \cdots & a_{n 2} \\
a_{13} & a_{23} & a_{33} & \cdots & a_{n 3} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{1 m} & a_{2 m} & a_{3 m} & \cdots & a_{n m}
\end{array}\right)
$$




```{admonition} Example
:class: tip

These examples come from {cite:ps}`shannon1995` (p. 139, Example 8).

- Example 1: If $
x=\left(\begin{array}{l}
1 \\
3 \\
5
\end{array}\right)
$ then $X^{T}=(1,3,5)$.  
<br></br>

- Example 2: If $
Y=\left(\begin{array}{ll}
2 & 3 \\
5 & 9 \\
7 & 6
\end{array}\right)
$ then $
Y^{T}=\left(\begin{array}{lll}
2 & 5 & 7 \\
3 & 9 & 6
\end{array}\right)
$.  
<br></br>

- Example 3: If $
Z=\left(\begin{array}{ccc}
1 & 3 & 7 \\
4 & 5 & 11 \\
6 & 8 & 10
\end{array}\right)
$ then $
Z^{T}=\left(\begin{array}{ccc}
1 & 4 & 6 \\
3 & 5 & 8 \\
7 & 11 & 10
\end{array}\right)
$.  
```


### Symmetric matrices

In general, $A^{T} \neq A$. There are two reasons for this:
- First, unless $A$ is a square matrix (that is, unless it has the same number of rows and columns), the dimensions of the matrix $A^{T}$ will be different to the dimensions of the matrix $A$.
- Second, even if $A$ is a square matrix, in general the $i$th row of $A$ will not be identical to the $i$th column of $A$. As such, in general we will have $A^{T} \neq A$ even for square matrices.

If it is the case that $A^{T}=A$, then we say that $A$ is a **symmetric matrix**.


```{admonition} Example
:class: tip

- Example 1:
$
A=\left(\begin{array}{ll}
0 & 0 \\
0 & 0
\end{array}\right)=A^{T}
$
<br></br>

- Example 2:
$
B=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)=B^{T} 
$
<br></br>

- Example 3:
$
C=\left(\begin{array}{ll}
0 & 1 \\
1 & 0
\end{array}\right)=C^{T} 
$
<br></br>

- Example 4:
$
D=\left(\begin{array}{ll}
1 & 0 \\
0 & 0
\end{array}\right)=D^{T} 
$
```

### Identity matrices

An **identity matrix** is a square matrix that has ones on the main (north-west to south-east) diagonal and zeros everywhere else. For example, the $(2 \times 2)$ identity matrix is

$$
I=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)
$$

The $(n \times n)$ identity matrix is the MULTIPLICATIVE identity matrix for any relevant space of matrices:
- If $A$ is an $(n \times n)$ matrix, then $A I=I A=A$.
- If $A$ is an $(m \times n)$ matrix, then $A I=A$.
- If $A$ is an $(n \times m)$ matrix, then $I A=A$.


### Multiplicative inverses

Only square matrices have any chance of having a multiplicative inverse. Some, but not all, square matrices will have a multiplicative inverse. Suppose that $A$ is an $(n \times n)$ matrix and $I$ is the $(n \times n)$ identity matrix.

The $(n \times n)$ matrix $B$ is the **multiplicative inverse** (usually just referred to as the inverse) of $A$ if and only if $A B=B A=I$.

- A square matrix that has an inverse is said to be **non-singular**.
- A square matrix that does not have an inverse is said to be **singular**.
- We will talk about methods for determining whether or not a matrix is non-singular later in this unit.
- We will talk about methods for finding an inverse matrix, if it exists, later in this unit.
- Useful fact: "The transpose of the inverse is equal to the inverse of the transpose".
    - If $A$ is a non-singular square matrix whose multiplicative inverse is $A^{-1}$, then we have $\left(A^{-1}\right)^{T}=\left(A^{T}\right)^{-1}$.


#### An example of a multiplicative inverse matrix

This example comes from {cite:ps}`haeussler1987` (p. 278, Example 1).
- Note that

$$
\begin{aligned}
A B &=\left(\begin{array}{ll}
1 & 2 \\
3 & 7
\end{array}\right) \cdot\left(\begin{array}{cc}
7 & -2 \\
-3 & 1
\end{array}\right) \\[10pt]
&=\left(\begin{array}{cc}
(1)(7)+(2)(-3) & (1)(-2)+(2)(1) \\
(3)(7)+(7)(-3) & (3)(-2)+(7)(1)
\end{array}\right) \\[10pt]
&=\left(\begin{array}{cc}
7+(-6) & -2+2 \\
21+(-21) & -6+7
\end{array}\right) \\[10pt]
&=\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right) \\[10pt]
&= I
\end{aligned}
$$

Note that

$$
\begin{aligned}
B A &=\left(\begin{array}{cc}
7 & -2 \\
-3 & 1
\end{array}\right) \cdot\left(\begin{array}{cc}
1 & 2 \\
3 & 7
\end{array}\right) \\[10pt]
&=\left(\begin{array}{cc}
(7)(1)+(-2)(3) & (7)(2)+(-2)(7) \\
(-3)(1)+(1)(3) & (-3)(2)+(1)(7)
\end{array}\right) \\[10pt]
&=\left(\begin{array}{cc}
7+(-6) & 14+(-14) \\
-3+3 & -6+7
\end{array}\right) \\[10pt]
&=\left(\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}\right) \\[10pt]
&= I
\end{aligned}
$$

Since $A B=B A=I$, we can conclude that $A^{-1}=B$.







## Multivariate calculus

```{admonition} Reminder of the derivative in one dimension
:class: caution

Let $f \colon (a, b) \to \mathbb{R}$ and let $x \in (a, b)$

Let $H$ be all sequences $\{h_n\}$ such that 
$h_n \ne 0$ and $h_n \to 0$

If there exists a constant $f'(x)$ such that
%
$$
\frac{f(x + h_n) - f(x)}{h_n} \to f'(x)
$$
%
for every $\{h_n\} \in H$, then 

- $f$ is said to be ***differentiable*** at $x$
- $f'(x)$ is called the ***derivative*** of $f$ at $x$ 

```

In higher dimensions this definition has to be adjusted to account for the fact that $h_n$ is a vector in $\mathbb{R}^N$

```{admonition} Definition
:class: caution
:name: jacobian

Let 
- $A \subset \mathbb{R}^N$ be an open set in $N$-dimensional space.
- $f \colon A \to \mathbb{R}^K$ be a $K$ dimensional vector function
- ${\bf x} \in A$, and so $\exists \epsilon \colon B_{\epsilon}({\bf x}) \subset A$

Then if there exists a $K \times N$ matrix $J$ such that
%
$$
\frac{\|f({\bf x} + {\bf h}_n) - f({\bf x}) - J {\bf h}_n\|}{\|{\bf h}_n\|} \to 0
$$
%
for all converging to zero sequences $\{{\bf h}_n\}$, ${\bf h}_n \in B_{\epsilon}({\bf 0}) \setminus \{{\bf 0}\}$, ${\bf h}_n \to {\bf 0}$,
then 

- $f$ is said to be ***differentiable*** at ${\bf x}$
- matrix $J$ is called the ***total derivative*** (or ***Jacobian*** matrix) of $f$ at ${\bf x}$, and is denoted by $Df({\bf x})$ or simply $f'({\bf x})$
```

```{note}
The vector function $f \colon \mathbb{R}^N \to \mathbb{R}^K$ (also known as *vector-valued* function) 
can be thought of as a tuple of $K$ functions 
$f_j \colon \mathbb{R}^N \to \mathbb{R}$, $j \in \{1, \dots, K\}$
```

Contrast the definition of total derivative to the definition of the *partial derivative*

```{admonition} Definition
:class: caution
:name: partial-derivative

Let $f \colon A \to \mathbb{R}$ and let ${\bf x} \in A \subset \mathbb{R}^N$.
Denote ${\bf e}_i$ the $i$-th unit vector in $\mathbb{R}^N$, i.e. ${\bf e}_i = (0, \dots, 0, 1, 0, \dots, 0)$ where $1$ is in the $i$-th position.

If there exists a constant $a \in \mathbb{R}$ such that 
%
$$
\frac{\| f({\bf x} + h_n {\bf e}_i) - f({\bf x})\|}{h_n} \to a
$$
%
for every sequence $\{h_n\}$, $h_n \in \mathbb{R}$, 
such that $h_n \ne 0$ and $h_n \to 0$ as $n \to \infty$, then 
$a$ is called a **partial derivative** of $f$ with respect to $x_i$ at ${\bf x}$, and is denoted $f'_i({\bf x})$ or $\frac{\partial f}{\partial x_i}({\bf x})$

```

Total derivative of $f \colon \mathbb{R}^N \to \mathbb{R}^K$ defines a linear map $J \colon \mathbb{R}^N \to \mathbb{R}^K$ given by $K \times N$ matrix $Df(x)$ which gives a *affine* approximation of function $f$ by a tangent hyperplane at point ${\bf x}$.
This is similar to the tangent line to a one-dimensional function determined by a derivative at any given point.

```{admonition} Fact
:class: important

If a vector function $f \colon \mathbb{R}^N \to \mathbb{R}^K$ is differentiable at ${\bf x}$, then all partial derivatives at ${\bf x}$ exist and the total derivative (Jacobian) is given by
%
$$
Df({\bf x}) =
\left(
\begin{array}{ccc}
\frac{\partial f_1}{\partial x_1}({\bf x}) & 
\cdots &
\frac{\partial f_1}{\partial x_N}({\bf x}) \\
\vdots & \ddots & \vdots \\
\frac{\partial f_K}{\partial x_1}({\bf x}) &
\cdots & 
\frac{\partial f_K}{\partial x_N}({\bf x})
\end{array}
\right)
$$
%
```

```{admonition} Fact
:class: important

If all partial derivatives of $f \colon \mathbb{R}^N \to \mathbb{R}^K$ exist and are continuous in ${\bf x}$, then $f$ is differentiable at ${\bf x}$

```

The last two facts can be stated for sets by adding the condition that the statements hold in all elements on the sets (such as "for all ${\bf x} \in A$")

```{admonition} Example
:class: tip

%
$$
f \colon
\left(
\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}
\right)
\mapsto
\left(
\begin{array}{l}
x_1^2 + x_2 x_3 \\
x_1+x_2^2+x_3^3
\end{array}
\right)
$$
%
Partial derivatives are
%
$$
\frac{\partial f_1}{\partial x_1} = 2 x_1, \;
\frac{\partial f_1}{\partial x_2} = x_3, \;
\frac{\partial f_1}{\partial x_3} = x_2 
$$
%
$$
\frac{\partial f_2}{\partial x_1} = 1, \;
\frac{\partial f_2}{\partial x_2} = 2x_2, \;
\frac{\partial f_2}{\partial x_3} = 3x_3^2
$$
%
Jacobian matrix is
%
$$
Df({\bf x}) = 
\left(
\begin{array}{rrr}
2x_1, & x_3, & x_2 \\
1, & 2x_2, & 3x_3^2
\end{array}
\right)
$$
%
Now, evaluating at a particular points
%
$$
Df({\bf 0}) = 
\left(
\begin{array}{rrr}
0, & 0, & 0 \\
1, & 0, & 0
\end{array}
\right)
$$
%
$$
Df({\bf 1}) = 
\left(
\begin{array}{rrr}
2, & 1, & 1 \\
1, & 2, & 3
\end{array}
\right)
$$
%
$$
Df((1,2,3)') = 
\left(
\begin{array}{rrr}
2, & 3, & 2 \\
1, & 4, & 27
\end{array}
\right)
$$
%

```

```{admonition} Example
:class: tip

%
$$
f \colon
\left(
\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}
\right)
\mapsto
\left(
\begin{array}{l}
x_1 + x_1 x_2 x_3 \\
x_1+2x_2-x_3 \\
x_1+2x_3 \\
x_2x_3
\end{array}
\right)
$$
%

**Exercise:** Derive Jacobian maxtix of $f$ and compute the  total derivative of $f$ at ${\bf x} = (1, 0, 2)$

```

```{admonition} Definition
:class: caution
:name: gradient

For a function $f \colon \mathbb{R}^N \to \mathbb{R}$ the Jacobian matrix takes is $1 \times N$ vector which is called ***gradient*** and is often denoted $\nabla f({\bf x}) \in \mathbb{R}^N$
%
$$
\nabla f({\bf x}) = \left(\frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_N} \right) \in \mathbb{R}^N
$$

```

### Rules of differentiation

```{admonition} Fact
:class: important

Let $A$ denote an open set in $\mathbb{R}^N$ and let $f, g \colon A \to \mathbb{R}^K$ be differentiable functions at ${\bf x} \in A$.

1. $f+g$ is differentiable at ${\bf x}$ and $D(f+g)({\bf x}) = Df({\bf x}) + Dg({\bf x})$
2. $cf$ is differentiable at ${\bf x}$ and $D(cf)({\bf x}) = c Df({\bf x})$ for any scalar $c$

```

```{admonition} Fact: Product (Leibniz) rule
:class: important

Let $A$ denote an open set in $\mathbb{R}^N$ and let $f \colon A \to \mathbb{R}$ and $g \colon A \to \mathbb{R}^K$ be both differentiable functions at ${\bf x} \in A$.

Then $f g$ is differentiable at ${\bf x}$ and $D(f g)({\bf x}) = f({\bf x}) Dg({\bf x}) + g({\bf x}) \nabla f({\bf x})$

```

% ```{admonition} Definition
% :class: caution
% 
% Outer product of two vectors ${\bf x} \in \mathbb{R}^N$ and ${\bf y} \in \mathbb{R}^K$ is a $N \times K$ matrix given by
% %
% $$
% {\bf x} {\bf y}' =
% \left(
% \begin{array}{c}
% x_1 \\ \vdots \\ x_N
% \end{array}
% \right)
% (y_1,\dots,y_K)
% =
% \left(
% \begin{array}{lll}
% x_1 y_1 & 
% \cdots &
% x_1 y_K \\
% \vdots & \ddots & \vdots \\
% x_N y_1 &
% \cdots & 
% x_N y_K
% \end{array}
% \right)
% $$
% 
% ```
% 


```{admonition} Fact: Dot product rule
:class: important

Let $A$ denote an open set in $\mathbb{R}^N$ and let $f,g \colon A \to \mathbb{R}^K$ be both differentiable functions at ${\bf x} \in A$.

Then $f \cdot g$ is differentiable at ${\bf x}$ and $D(f \cdot g)({\bf x}) = [f({\bf x})]' Dg({\bf x}) + [g({\bf x})]' Df({\bf x})$, where $[\cdot]'$ denotes vector transpose

```

```{admonition} Fact: Chain rule
:class: important

Let $A$ denote an open set in $\mathbb{R}^N$ and $C$ denote an open set in $\mathbb{R}^K$.
Let $f \colon A \to C$ be differentiable at ${\bf x} \in A$, and
$g \colon C \to \mathbb{R}^L$ be differentiable at $f({\bf x}) \in C$.

Then the composition $g \circ f$ is differentiable at ${\bf x}$ and its total derivatibe is given by $D(g \circ f)({\bf x}) = Dg(f({\bf x})) Df({\bf x})$

```



```{admonition} Example
:class: tip

%
$$
f \colon
\left(
\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}
\right)
\mapsto
\left(
\begin{array}{l}
x_1^3 + x_2 x_3 \\
x_2+x_1 x_3^2
\end{array}
\right)
$$
%
$$
Df({\bf x}) = 
\left(
\begin{array}{lll}
3x_1^2, & x_3, & x_2 \\
x_3^2, & 1, & 2x_1x_3
\end{array}
\right)
$$
%
$$
g \colon
\left(
\begin{array}{c}
y_1 \\
y_2
\end{array}
\right)
\mapsto
\left(
\begin{array}{l}
2 y_1^2 \\
y_1 + y_2 \\
y_1 - y_2 \\
4 y_2^2 \\
\end{array}
\right)
$$
%
$$
Dg({\bf y}) = 
\left(
\begin{array}{lll}
4y_1, & 0 \\
1, & 1 \\
1, & -1 \\
0, & 8y_2
\end{array}
\right)
$$
%
Applying the chain rule
%
$$
D(g \circ f)({\bf x}) = 
\left(
\begin{array}{lll}
4(x_1^3 + x_2 x_3), & 0 \\
1, & 1 \\
1, & -1 \\
0, & 8(x_2+x_1 x_3^2)
\end{array}
\right)
\left(
\begin{array}{lll}
3x_1^2, & x_3, & x_2 \\
x_3^2, & 1, & 2x_1x_3
\end{array}
\right)
$$
%
$$
D(g \circ f)({\bf x}) = 
\left(
\begin{array}{lll}
12x_1^2(x_1^3 + x_2 x_3), & 
4x_3(x_1^3 + x_2 x_3), & 
4x_2(x_1^3 + x_2 x_3)\\
3x_1^2+x_3^2, &
x_3+1, &
x_2+2x_1x_3 \\
3x_1^2-x_3^2, &
x_3-1, &
x_2-2x_1x_3 \\
8x_3^2(x_2+x_1 x_3^2), &
8(x_2+x_1 x_3^2), &
16 x_1 x_3(x_2+x_1 x_3^2)
\end{array}
\right)
$$

Now we can evaluate $D(g \circ f)({\bf x})$ at a particular points in $\mathbb{R}^3$

```

```{admonition} Example
:class: tip

$$
f \colon
\left(
\begin{array}{c}
x_1 \\
x_2
\end{array}
\right)
\mapsto
\left(
\begin{array}{l}
x_1^2 + x_2^2 \\
x_1 x_2
\end{array}
\right)
$$
%
$$
g \colon
\left(
\begin{array}{c}
y_1 \\
y_2
\end{array}
\right)
\mapsto
(y_1+2 y_2)^2
$$
%
**Exercise:** Using the chain rule, find the total derivative of the composition $g \circ f$.

```

- The chain rule very powerful tool in computing complex derivatives (think backwards propagation in deep neural networks)

### Total derivative and directional derivative





### Higher order derivatives

The higher order derivatives of the function in one dimension generalize naturally to the multivariate case, but the complexity of the needed matrixes and multidimensional arrays (*tensors*) grows fast.

```{admonition} Definition
:class: caution
:name: hessian

Let $A$ denote an open set in $\mathbb{R}^N$, and let $f \colon A \to \mathbb{R}$. Assume that $f$ is twice differentiable at ${\bf x} \in A$.

The total derivative of the gradient of function $f$ at point ${\bf x}$, $\nabla f({\bf x})$ is called the ***Hessian*** matrix of $f$ denoted by $Hf$ or $\nabla^2 f$, and is given by a $N \times N$ matrix
%
$$
Hf({\bf x}) = \nabla^2 f({\bf x}) = 
\left(
\begin{array}{ccc}
\frac{\partial^2 f}{\partial x_1 \partial x_1}({\bf x}) & 
\cdots &
\frac{\partial^2 f}{\partial x_1 \partial x_N}({\bf x}) \\
\vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_N \partial x_1}({\bf x}) &
\cdots & 
\frac{\partial^2 f}{\partial x_N \partial x_N}({\bf x})
\end{array}
\right)
$$
```
```{admonition} Fact
:class: important

For every ${\bf x} \in A \subset \mathbb{R}^N$ where $A$ is an open and $f \colon A \to \mathbb{R}^N$ is twice continuously differentiable, the Hessian matrix $\nabla^2 f({\bf x})$ is symmetric
```

```{admonition} Example
:class: tip

$$
f \colon
\left(
\begin{array}{c}
x_1 \\
x_2
\end{array}
\right)
\mapsto
(x_1 - 2 x_2)^2
$$
%
$$
\nabla^2 f({\bf x}) = 
\left(
\begin{array}{rr}
2, & -4 \\ -4, & 8
\end{array}
\right)
$$
%
**Exercise:** check
```

```{admonition} Example
:class: tip

$$
f \colon
\left(
\begin{array}{c}
x_1 \\
x_2
\end{array}
\right)
\mapsto
(x_1 - 2 x_2)^3
$$
%
$$
\nabla^2 f({\bf x}) = 
6 (x_1 - 2 x_2) 
\left(
\begin{array}{rr}
1, & -2 \\ -2, & 4
\end{array}
\right)
$$
%
**Exercise:** check
```


NOTES:
- Linear, quadratic form examples
- Logit example from exercise F